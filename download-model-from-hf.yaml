apiVersion: batch/v1
kind: Job
metadata:
  name: download-model-from-hf
  namespace: demo
spec:
  backoffLimit: 3
  template:
    spec:
      containers:
        - name: download-model
          image: python:3.11-slim
          command:
            - /bin/bash
            - -c
            - |
              set -e
              export HOME=/tmp/home
              export PYTHONUSERBASE=/tmp/home/.local
              mkdir -p $HOME/.local

              echo "Installing huggingface-hub..."
              pip install --user --no-cache-dir -q huggingface-hub
              export PATH="$HOME/.local/bin:$PATH"

              echo "Downloading the model..."
              python3 << 'PYTHON_SCRIPT'
              import os
              import sys
              from huggingface_hub import snapshot_download

              model_id = "google/embeddinggemma-300m"
              local_dir = "/mnt/models"
              token = os.environ.get('HF_TOKEN')

              if not token:
                  print("ERROR: HF_TOKEN environment variable is not set", file=sys.stderr)
                  sys.exit(1)

              try:
                  os.makedirs(local_dir, exist_ok=True)
                  snapshot_download(
                      repo_id=model_id,
                      local_dir=local_dir,
                      token=token,
                      resume_download=True
                  )
                  print(f"Downloaded files to {local_dir}: {os.listdir(local_dir)}")
              except Exception as e:
                  print(f"Error during download: {e}", file=sys.stderr)
                  import traceback
                  traceback.print_exc()
                  sys.exit(1)
              PYTHON_SCRIPT

              echo "Verifying downloaded files..."
              ls -lah /mnt/models
              du -sh /mnt/models
          env:
            - name: HF_TOKEN
              valueFrom:
                secretKeyRef:
                  key: token
                  name: huggingface-token
          resources:
            requests:
              cpu: "2"
              memory: 4Gi
            limits:
              cpu: "4"
              memory: 8Gi
          securityContext:
            fsGroup: 1001080001
            runAsGroup: 1001080001
            runAsUser: 1001080001
          volumeMounts:
            - mountPath: /mnt/models
              name: llm-storage
      restartPolicy: Never
      volumes:
        - name: llm-storage
          persistentVolumeClaim:
            claimName: pvc-encoder
